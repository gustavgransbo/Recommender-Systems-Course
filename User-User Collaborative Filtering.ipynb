{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-User Collaborative Filtering\n",
    "In this notebook I will perform the task of [lecture 23](https://www.udemy.com/recommender-systems/learn/lecture/11717432), which is to predict movie ratings of users using user-user collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Data\n",
    "The data that I will classify comes from the MovieLens20M data set, containing 20 million user ratings (1-5 stars) of movies in the MovieLens database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movielens_df = pd.read_csv('large_files/rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000263, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp\n",
       "0       1        2     3.5  2005-04-02 23:53:47\n",
       "1       1       29     3.5  2005-04-02 23:31:16\n",
       "2       1       32     3.5  2005-04-02 23:33:39\n",
       "3       1       47     3.5  2005-04-02 23:32:07\n",
       "4       1       50     3.5  2005-04-02 23:29:40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId     138493\n",
       "movieId     26744\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_df.loc[:,['userId', 'movieId']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the data\n",
    "I would like to avoid having to deal with a 138k X 26k matrix of user-ratings.\n",
    "The course suggests only considering the top most active users and most rated movies.\n",
    "For movies this might make sense, we could consider only recommending movies we have a lot of data bout, but when it comes to users I see this as a little bit of a cheat, since it automatically discards the hardest cases, i.e. providing recommendations for users we have little data for.\n",
    "\n",
    "So, I will be keeping the top most rated movies, but a random subset of users (subject to some limitations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select top movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_most_rated_movies = movielens_df['movieId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Distribution of ratings for all movies')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAEqCAYAAAD53kJbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 4.5))\n",
    "ax.plot(np.arange(len(top_most_rated_movies)), top_most_rated_movies.values);\n",
    "ax.set_ylabel('ratings')\n",
    "ax.set_xlabel('rank')\n",
    "ax.set_title('Distribution of ratings for all movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of ratings per movie follows a clear power law, with a small fraction of movies having a large number of ratings. Let's select the top 2,500 movies for our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_movies = top_most_rated_movies[:2500].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_movies_df = movielens_df.loc[movielens_df.loc[:,'movieId'].isin(top_movies),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are down to 84.85 % of all reviews\n"
     ]
    }
   ],
   "source": [
    "print(\"We are down to %.2f %% of all reviews\" % (100 * top_movies_df.shape[0] / movielens_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_per_user = top_movies_df['userId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Distribution of ratings for all users')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAEqCAYAAADj4qLVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcXHWZ7/FPLV29L9lIyEYIkSdt\n2CQgEFmi6GSAGZjL1dFxcETGHR2413FwFARnnHHcR0RhRkBwFEcWuW4X4SoCkVWaIASaJ6whkITs\nS3enu7q66v5xTnWKprtTHbq6+lR93y/yStU5v3PqeaqbPOf3O79zTiyXyyEiIiLRFi93ACIiIvL6\nqaCLiIhUABV0ERGRCqCCLiIiUgFU0EVERCqACrqIiEgFSJY7AJHxZGYLgGeBx8NFcaAL+Hd3vzFs\n80/AM+7+g1H283ngj+7+s2HWDW5vZjlghrtvGUOMxwJ/6+4fNbNjgM+4+zuL3X5/mFkC+CnQDlzu\n7lfs534Gv5divsfXa7ziHmX/5wLvdPc/M7O7gCvc/ebx/AyRiaKCLpVoj7sflX9jZgcBvzWzAXe/\nxd0/X8Q+3gY8OdyKIrcfzRJgbrivh4GSFvPQHGAF0OjuA69jP4Pfyzh8D8UYr7hFKp4KulQ8d18b\n9iw/DdxiZtcBq939a2b2BeB/AGlgK3AucDZwDPBVMxsAzgKmAocAvwRm5rcPP+Jfwl53HLjY3X9Z\n2PODvT1B4GPAPwGtZvZ94HqCXuFhZtYKfAc4CsgBtwGfdfeMmfUC/wb8CXAg8BV3v3JormZ2EvBV\noCHM6WLgXuDXQA3QYWb/092fLdjmuiH5XRPG0Rx+1qPAu4G/HeZ7yX+Pw8YX9rC/CpwJ7AQeBN7o\n7svN7OwwviwwAHza3e8piKt5aNzA7KH5ufuvw+/3b4FGYKe7v3XI93Ie8BEgFeb6b8N9f8MZ2nMv\nfD/c74+7bzCzduBbwDQgQTC6cK2ZLQ+XdwNNwEnA1cAbwu+hA/iIu2eLiU2kkM6hS7X4I3B44QIz\nmwdcCBzr7scAdwDHuft3gIcJCsytYfMGd1/i7hcNs+/n3P1o4BzgejObMVIQ7r4O+Dyw0t0/MGT1\n5QRF4XCCwnkk8Pfhulpgi7svIzgw+KaZ1Q3JZxpwM3CBux8BvB/4ITAdOJ1w5KKwmBcozO9DwPXu\nfjywCDgYOGOE7yVvpPg+CCwFDgNOIDhoyPsq8PHwu78EWD7ku9pdGDewY7j8zOzgcJMlwPJhinlT\nmNPp7v4mgoOTrwzzHYzJSL8/ZpYM4/yMuy8FTgH+3syODzc9DPirMIczgeYwv2PD9Qtfb2xSnVTQ\npVrkgJ4hy14mKPSPmNnXgEfd/f+MsP3vR9n3VQDuvppgOPqE/YzxNIKeX87d+8L9nlawPn8+/xGC\nAto4ZPvjCM5pPxjG8wRB73x5EZ9dmN9FwGYz+wfgSoJecVMR+xguvtOBH7h7r7ungf8oaP/fwK1m\ndjUwhX0X2X3l95i77xq6kbt3AX8GnGFm/wx8rsh89mWk359DCQ5crjWzR4G7gXrgTeF269x9bfj6\n98CSsNf/GYK5Hs+MQ2xShVTQpVocy96JcgCEw5qnEAyzbyXoVY5UVLpG2Xfhud040E9wABErWJ4q\nIsZ4uF3h+5qC93vCuPNtCvcPwdDu0IczDN3HSArz+zHwYWAt8E2CAj30s4YzXHyZIdsOflfu/jng\nRIJe/7nAPYxuX/kN+zMys7kEpw0OIiigF+/jc4Ya9mc5yu9PgmDY/6j8H+B44PtD43T35wlGQb4E\ntAC/MbM/H2N8IoAKulQBMzuUYEj360OWHwmsBjrd/UsExSs/7JmhuEIIwT/omNnRBP84PwhsBg4z\nszozq+HVE99G2vftwCfMLGZmtQRF9f8VGQPA/cBiM3tzGM8S4GTgrjHsA4JJaP/k7j8J3x9HUKRG\ni30kvwLOMbPacCj6XCBnZkkze4FgqP8q4OPAEWHeI9nf/I4h+Hl8kWBYPD+vITHaRgU2h/vAzN4I\nHBG+Hun3x4E9ZnZO2G5e2G7p0B2b2ccICv0d4emO24Gji4xL5FVU0KUS1ZvZo+GfR4DrgH90918V\nNnL3PwI3Ag+b2cPAecD/Dlf/HPiSmb2/iM9baGarCCY3vcfdtxEUjruBpwh6ng8XtH8g3OanQ/bz\nd8ABBCMJjxMUhn8pMmfCS+feBXzbzB4HbgA+4O5rit1H6LMEQ+GPEwyR301woAJj+14g+O4fBFYB\n9xFMHutx9wzB+ecbwp/RTcB54amG8c7vDuAlgu+zE5hPUKQXjbZRgS8Cf2JmqwkmNN4TxjPs7094\nauEs4INm9lj4+Ze4+73D7PsHBAdLT5pZB9BKMJdCZMxienyqiJSKmf0JcIC7/zB8/y2gd4TJhSLy\nOuiyNREppSeAT4cT7BIEk8g+Vt6QRCqTeugiIiIVQOfQRUREKoAKuoiISAUY93Po4SU61wILCG4u\n8UWCGaa/AJ4Om13p7j8xs0uBMwguhbnQ3R8ys0UEM2NzBJd6nK/bIIqIiIyuFJPizgG2uvv7wltR\nriK41OMb7j54HXB4ze4pBNe4zgNuIbiG8xsE92e+y8yuIrj8Y+htJuno6NDJfxERqSpLly4d8SZP\npSjoNxHcxzgvQ3BDBTOzswh66RcS3CHqjvCuUi+GN5qYEba9O9z2NoKHPbymoAMsXfqa+zTst87O\nTtrb28dtf5NZteRaLXmCcq1E1ZInVE+urzfPjo6OUdePe0EP75ucf1LSzQS3WawFrnb3DjP7HHAp\nwYMWthZsupvgpgqxgltH5pcNq7Ozc9zi7u3tHdf9TWbVkmu15AnKtRJVS55QPbmWOs+SXIce3urw\nVuC77n6DmbW5+45w9a3Atwke5NBcsFkzQZHPDrNsWON5RFctR4hQPblWS56gXCtRteQJ1ZNrqXvo\n4z7L3cxmEtzq8CJ3vzZcfHv+/svAqQTP/L0XWGFmcTObD8TDWzuuCp8ZDMGTplaOd4wiIiKVphQ9\n9M8SPArxEjO7JFz2v4F/N7M0sBH4sLvvMrOVBA9ciAPnh20/BXzPzFIE912+GRERERlVKc6hXwBc\nMMyqZcO0vQy4bMiyNQSz30VERKRIurGMiIhIBVBBFxERqQAq6CIiIhVABR34wf0v8I17N5U7DBER\nkf2mgg48+uIOHt/YW+4wRERE9psKuoiISAVQQQ/pSS8iIhJlKugAIz67RkREJBpU0EM5ddFFRCTC\nVNCBmLroIiIScSroIiIiFUAFHYipgy4iIhGngh7KaZ67iIhEmAo6muQuIiLRp4Ie0ix3ERGJMhV0\ndA5dRESiTwVdRESkAqighzTiLiIiUaaCjm4sIyIi0aeCnqcuuoiIRJgKOpoUJyIi0aeCHlIHXURE\nokwFHfXQRUQk+lTQQ+qhi4hIlKmgA7r5q4iIRJ0Kep666CIiEmEq6CIiIhVABR1NihMRkehTQQ9p\nxF1ERKJMBR1NiRMRkehTQQ/l1EcXEZEIU0FH59BFRCT6VNBDOXXQRUQkwlTQ0eNTRUQk+lTQRURE\nKoAKOjqHLiIi0aeCLiIiUgFU0EOaEyciIlGWHO8dmlkNcC2wAKgFvgg8CVxHUDdXA+e7e9bMLgXO\nADLAhe7+kJktGq7teMdZSCPuIiISdaXooZ8DbHX3k4DTgCuAbwAXh8tiwFlmdjRwCnAc8B7gO+H2\nr2lbghhfQ5etiYhIlJWioN8EXFLwPgMsBe4O398GvB04EbjD3XPu/iKQNLMZI7QtqZhmxYmISMSN\n+5C7u3cBmFkzcDNwMfA1d8/3gXcDrUALsLVg0/zy2DBth9XZ2TkuMW/bto1cLjdu+5vsent7qyLX\naskTlGslqpY8oXpyLXWe417QAcxsHnAr8F13v8HMvlKwuhnYAewKXw9dnh1m2bDa29vHJd6pTz9B\n7LmucdvfZNfZ2VkVuVZLnqBcK1G15AnVk+vrzbOjo2PU9eM+5G5mM4E7gIvc/dpw8SozWx6+Pg1Y\nCdwLrDCzuJnNB+LuvmWEtiWnc+giIhJlpeihfxaYAlxiZvlz6RcAl5tZCugEbnb3ATNbCdxPcGBx\nftj2U8D3CtuWIMZX0Sl0ERGJulKcQ7+AoIAPdcowbS8DLhuybM1wbUtNj08VEZEo041l0MNZREQk\n+lTQRUREKoAKekgD7iIiEmUq6GhSnIiIRJ8Kep666CIiEmEq6OjhLCIiEn0q6CF10EVEJMpU0NE5\ndBERiT4V9JB66CIiEmUq6OjxqSIiEn0q6CIiIhVABT1PY+4iIhJhKujosjUREYk+FfSQOugiIhJl\nKuigLrqIiESeCnoopy66iIhEmAo6eh66iIhEnwp6KKez6CIiEmEq6OjWryIiEn0q6CIiIhVABR1N\nchcRkehTQRcREakAKughXbYmIiJRpoKOJsWJiEj0qaCH1EEXEZEoU0FHN5YREZHoU0EXERGpACro\n6By6iIhEnwp6SLPcRUQkylTQ0Y1lREQk+lTQRUREKoAKOhCLxcgB2azG3UVEJJpU0IGaRDDonlFB\nFxGRiFJBB5KJ4GvIZLNljkRERGT/qKADybh66CIiEm0q6BQU9AEVdBERiSYVdAqG3Ac05C4iItGk\ngs7eSXH9GnIXEZGIUkEHknH10EVEJNqSpdqxmR0HfNndl5vZ0cAvgKfD1Ve6+0/M7FLgDCADXOju\nD5nZIuA6gieargbOd/eSVtpkvoeuc+giIhJR+yzoZnYy0EDQm/82cIm737CPbf4BeB/QHS46GviG\nu3+9oM3RwCnAccA84BbgWOAbwMXufpeZXQWcBdw6xrzGJN9DH9CQu4iIRFQxQ+5fIehZ/x3wFuCj\nRWzzLHB2wfulwBlmdo+ZXWNmzcCJwB3unnP3F4Gkmc0I294dbncb8PbiUtl/e3voGnIXEZFoKmbI\nfQ/wCpBx941mVruvDdz9FjNbULDoIeBqd+8ws88BlwI7gK0FbXYDrUDM3XNDlg2rs7OziPD3beP6\nHgCeefY5ErvqxmWfk1lvb++4fXeTWbXkCcq1ElVLnlA9uZY6z2IK+i7gN8B3zex84MX9+Jxb3X1H\n/jXB0P3PgOaCNs0ERT47zLJhtbe370cor7U5sRnYyNz5B9G+YOq47HMy6+zsHLfvbjKrljxBuVai\naskTqifX15tnR0fHqOuLGXL/S+A8d/8BwVD4OfsRx+1m9ubw9alAB3AvsMLM4mY2H4i7+xZglZkt\nD9ueBqzcj88bE02KExGRqCumhz4d+Gx4fvtmoBF4cIyf8zHgCjNLAxuBD7v7LjNbCdxPcGBxftj2\nU8D3zCwFdIafWVI1CU2KExGRaCumoP8n8HXgEuAe4Hrg+H1t5O4v5Nu5+yPAsmHaXAZcNmTZGoLZ\n7xMmEc/fWEaT4kREJJqKGXKvc/c7gZy7O9Bb4pgmXM3gjWXUQxcRkWgqpqD3mdkKIGFmx1OBBT1/\nDl13ihMRkagqpqB/GPgAwbn0vyc4H15RdC93ERGJuhHPoZtZ0t0zwCbgbyYupImne7mLiEjUjTYp\n7gfAewEnuK86QCx8vbDEcU2o/KS4jHroIiISUSMWdHd/b/jyf7j7oxMUT1nUJDQpTkREoq2Yy9b+\n2cymAd8HfuzuXSWOacINTorTZWsiIhJR+5wU5+5/TvCglTbgDjO7uuRRTbD8ZWu6U5yIiERVMbPc\nAWqA2rB9pnThlIcuWxMRkagr5nnovwXqgGuAU929ex+bRI4mxYmISNQV00O/0N3fAvyC4FGqFUeT\n4kREJOqKKejTzew54P8Bz5nZO0oc04RLxGPE0KQ4ERGJrmIK+j8DJ7r7UcBbgC+WNqTySMQ1KU5E\nRKKrmII+4O7rAdz9ZSrwXu4AyXhMk+JERCSyirkOfZeZfZLg0aknA9tKG1J5JOMxTYoTEZHIKqaH\nfg4wH/gXYB5wXkkjKpN4TOfQRUQkukZ7OMv8grffLnjdDGwvWURlEgy5q4cuIiLRNNqQ+wvhn40F\ny/IPZ1lWupDKIxmPaVKciIhE1mgF/Z3AuwluKnMT8FN375mQqMogEdeQu4iIRNeI59Dd/afu/m6C\nZ6HXAj8xs+vNbMWERTeBNOQuIiJRVszDWXa6+zXAvwINwHWlDqocEpoUJyIiETbqZWtmdgTwXuA0\nYBVwNcEwfMVJqIcuIiIRNtos9yfClz8mGHbP38d9EbCmxHFNuFQiRm9moNxhiIiI7JfReuibCWa0\nnwq8LVyWn+X+tpE2iqq6ZJyetAq6iIhE04gF3d2XT2AcZVdfE2NLX8U96l1ERKpEMXeKqwr1NXG6\n+9RDFxGRaFJBD9Un4/Sk1UMXEZFoUkEP1dXE6NY5dBERiajRZrlvIJgAV0tw/fk6YC6wyd0XTEh0\nE6g+GSedyZLOZEkldZwjIiLRMtqd4g5099nAbcCh7n4owSVrD05UcBOpMRV8Fd2aGCciIhFUTFd0\nobuvA3D39QSPUq04dckYAN06jy4iIhE06p3iQk+a2X8BDwEnACtLG1J51NcExzZ7dB5dREQiqJiC\n/mGCW7++Efhvd/95aUMqj/rwvPmuXvXQRUQkeooZcm8k6JkvBpJmtqi0IZVHU3gOvUvn0EVEJIKK\nKejXAs8BhwIbgWtKGlGZNIRD7rt7+8sciYiIyNgVU9Cnufu1QL+730dwP/eK05DvoWvIXUREIqio\nC67NbHH491ygImeN7e2hq6CLiEj0FDMp7u+A7wPtwM3Ax0oaUZnU18RIxGPs2JMudygiIiJjVkxB\nX+DuJ+TfmNlfAqv2tZGZHQd82d2XhxPpriO489xq4Hx3z5rZpcAZQAa40N0fGqnt2NIau3gsxpSG\nGp7asLvUHyUiIjLuRrv1658BbwH+ysyWhYvjwFnAjaPt1Mz+AXgf0B0u+gZwsbvfZWZXAWeZ2Vrg\nFOA4YB5wC3DscG2BW/czvzEZyOaIVeQMARERqXSjnUP/I/AUsAfw8M8TwF8Vsd9ngbML3i8F7g5f\n3wa8HTgRuMPdc+7+IsElcTNGaDshlsxuZWu3htxFRCR6Ruyhh7d7vd7M/qtwyNvMDtzXTt39FjNb\nULAo5u658PVuoBVoAbYWtMkvH67tsDo7O/cVStF6e3upzfayZmvvuO53MurtrfwcoXryBOVaiaol\nT6ieXEudZzHn0C81s48DKYKnrq0BlozxcwrPgTcDO4Bd4euhy4drO6z29vYxhjGyzs5O3jCvnnvW\nPsfixYuJVfDYe2dn57h+d5NVteQJyrUSVUueUD25vt48Ozo6Rl1fzGVrpxE8NvVHBDPdX96POFaZ\n2fKC/a0E7gVWmFnczOYDcXffMkLbCTGrpZb+gZyG3UVEJHKKKehb3b0PaHb3Zwh66WP1KeALZnY/\nQU//ZnfvICjW9xNMiDt/pLb78Xn7ZVZrPQAbd/ZO1EeKiIiMi2KG3F8ys/OAbjP7EsG5731y9xeA\n48PXawhmtA9tcxlw2ZBlw7adCLNa64CgoB82Z8RT9yIiIpNOMT30jwC/BT4NrAfeXdKIymhOW9BD\nX7e9p8yRiIiIjM1o16EngTOB7e7+u3DZTcC3qNCiPr0pRV1NnJe37yl3KCIiImMy2pD7jwju4Hag\nmS0Bnid40tq3JiKwcojFYsxqqWODzqGLiEjEjFbQD3H3Y8wsBXQAfcBb3b2iLxZcML2RF7Z277uh\niIjIJDLaOfRdAO6eDtv9SaUXc4C5U+pZt03n0EVEJFqKenwq8Iq7bytpJJPEvCkN7OrNsHNPf7lD\nERERKdpoQ+5LzOwGIFbwGgB3f2/JIyuTQ2Y0AbDmld0cu2BqmaMREREpzmgF/S8LXl9V6kAmi/bZ\nwWX2T21UQRcRkegY7eEsd4+0rpLNbq2jraGGJ9fvLHcoIiIiRSv2HHrViMViHDKjiWc2dZU7FBER\nkaKpoA9j8axmntqwm2w2t+/GIiIik4AK+jCOmtfG7r4Mz25WL11ERKJBBX0Yh88NHszyxPpdZY5E\nRESkOCrow1g4vYlUIk7nBhV0ERGJBhX0YaSScRYd0MSTKugiIhIRKugjeNP8NjrWbqd/IFvuUERE\nRPZJBX0Exy2cRk96gCd1Hl1ERCJABX0Exx0c3CXuoeer4hb2IiIScSroI5jZUsf8qQ08vFYFXURE\nJj8V9FEcu2AqDz2/TTeYERGRSU8FfRTHLZzK9p5+ntq4u9yhiIiIjEoFfRQnLpoOwL3PbClzJCIi\nIqNTQR/F7LZ6DprWwIOaGCciIpOcCvo+LDtkOvc9u4Xe/oFyhyIiIjIiFfR9OHXxAfSkB/jDC+ql\ni4jI5KWCvg/LFk2jvibBrx7bUO5QRERERqSCvg8NqSSnHT6LXz62gT1pDbuLiMjkpIJehHcunUtX\nX4bbVquXLiIik5MKehGOP3gaB01r4KaHXyp3KCIiIsNSQS9CPB7j7DfN5f7ntrJuW0+5wxEREXkN\nFfQivfOYuQD86MEXyxyJiIjIa6mgF2lOWz2nLj6AGx9ep8lxIiIy6aigj8F5Jx7Mtu40P12lc+ki\nIjK5qKCPwbJDprFkdgv/ec9zpDPZcocjIiIySAV9DGKxGBec+gbWbu3hJw+vK3c4IiIig1TQx+gd\nb5zJm+a38a3frKEnnSl3OCIiIoAK+pjFYjH+8bR2tnSlue6+F8odjoiICKCCvl/efPBUTj50Blfc\n+Qzrd+wpdzgiIiIkJ/LDzGwVsDN8+zzwH8C3gAxwh7t/wcziwHeBI4E+4IPu/sxExlmML5y5hBXf\nvIfLfv4E//k3x5Q7HBERqXITVtDNrA7A3ZcXLHsU+J/Ac8CvzOxoYAFQ5+4nmNnxwNeBsyYqzmId\nPL2R89+6iG/+Zg2/7XyFU9tnljskERGpYhM55H4k0GBmd5jZnWZ2MlDr7s+6ew64HTgVOBH4NYC7\nPwBM2u7vR05ZyMHTG7n4/6xme3e63OGIiEgVi+VyuQn5IDM7HDgeuBp4A3AbsMPdl4brzwMWArOA\nW9z9tnD5i8BCd3/VlPKOjo5cQ0PDuMXX29tLXV3dmLdb/coeLrp9A2+e28Alb51JPBYbt5hKZX9z\njZpqyROUayWqljyhenJ9vXn29PSwdOnSEYvMRJ5DXwM8E/bG15jZTmBqwfpmYAfQEL7Oiw8t5nnt\n7e3jFlxnZ+d+7a+9HbbHn+Vf/+9T/GJtnM+ctnjcYiqV/c01aqolT1Culaha8oTqyfX15tnR0THq\n+okccj+P4Hw4ZjaboHB3m9khZhYDVgArgXuB08N2xwOPT2CM++VDJy3k7KPncNXdz/KzR18udzgi\nIlKFJrKHfg1wnZn9HsgRFPgs8CMgQTDL/UEz+wPwDjO7D4gBH5jAGPdLLBbj384+ghe2dHPRLY9x\nyIwmDpvTWu6wRESkikxYQXf3NPDeYVYdP6RdFvjohAQ1jlLJON/966Wc9Z3fc+73/8CNHzmehTOa\nyh2WiIhUCd1YZhzNaq3jmvcfS19mgL/4zr089tKOcockIiJVQgV9nB02p5X//vDxpJIJzv3+H3hm\nU1e5QxIRkSqggl4CS2a3csOHjqN/IMu7rrqPh1/YVu6QRESkwqmgl8ihM5u59ePLqKtJcM41D3Ln\nU6+UOyQREalgKugltOiAZm7+2DJmtdRx3nUPc8WdTzNRN/IREZHqooJeYnPa6vnZJ07k7e0z+dod\na/jkj1exJz1Q7rBERKTCqKBPgNb6Gv7zfUv5yMkL+dXjGzj98pWsfnnnvjcUEREpkgr6BInHY/zj\n6e1c/4E3s2tPP2d9514+/7PV7O7tL3doIiJSAVTQJ9jJh87gt586hb88Zh4/fGAtf/rvK/n16g06\nty4iIq+LCnoZtDWk+NLZh3PTR5fRkErw0R8+wruuup9HXtxe7tBERCSiVNDLaOlBU7jtgpP4wplL\neGFrN2d/9z4++eNVrN3aXe7QREQkYiby4SwyjGQizvuXLeDso+fwnd89y7X3Ps+vV2/gXcfM4+PL\nD2HulPF75ruIiFQu9dAniea6Gj5z2mLu+fRbOftNc7nxD+s4+Su/4xM3PKIZ8SIisk/qoU8ys1rr\n+PI7j+ATb1vE1Suf48aHX+KXj23g8DmtvH/ZAv78yAOpTSbKHaaIiEwy6qFPUvOmNvCFsw7jvs+8\njc+ctpjdvf38/U1/5IQv3cmXf/0U67b1lDtEERGZRNRDn+SmNKb46CmH8OGTFnLXmk1cd99arrr7\nWa6861lOXDSddx87jxVLZpFK6thMRKSaqaBHRDwe422LZ/K2xTN5cWsPP/7Di9zc8RKf/PEqpjam\nOPPI2Zx51GzeNK+NWCxW7nBFRGSCqaBH0PxpDVz0p4v51DsO5bdPbeInf1jHfz2wluvue4H5Uxs4\n88jZnHHEgbQf2FLuUEVEZIKooEdYMhFnxZJZrFgyi23daX71+AZ+/ujLXPG7Z7jid8+wcEYjK5bM\n4tTFB3DUvDaSCQ3Li4hUKhX0CjG1McX7jj+I9x1/EBt39vLLx9Zz2+qNXHlXcL69MZXgLYumc/Kh\nM5ib6Ke93AGLiMi4UkGvQLNa6/jgSQv54EkL2by7j5VPb2bl01tY+fRm7njyFQAW3rONZYdM49gF\nUzlh4TQOaKkrc9QiIvJ6qKBXuBnNtZx99FzOPnou2WyOzo27uHHlE/jOGDf+4SV++MCLABwyo5Fj\nDprK0Qe1ccTcNmxmM/G4JteJiESFCnoVicdjLJndynuOmEJ7ezv9A1keXbeD+57ZygPPbeXnf1zP\nTx5eB0BtMs7hc1o5fG4rR8xt5Yi5bRw8rVFFXkRkklJBr2I1iTjHLpjKsQumcgFvIDOQ5elNXTz2\n0g4eXbeTx17awQ/uX8tANni0a2MqQfuBLRw2p5Uls1toP7CFxbOaNdlORGQSUEGXQclEnPYDg0L9\n7mODZelMls4Nu3jspR08sX4Xq9fv5IcPrCUTFvlEPMahM5tpn9WMzWoOXh/YwsyWWl0PLyIygVTQ\nZVSpZJwj57Vx5Ly2wWX9A1mefqWLJzfs4on1O+ncsIs7fRM/XfXyYJvmuiQLZzSxeGYziw5o4g0z\nmzhkRhNzp9Sr0IuIlIAKuoxZTSLOG2e38MbZLbxz6VwAcrkcW7rSdG7YhW/czdObdvP0pi5+9fgG\nuvoyg9umEnEWTG9gwbRGDp4oGCG6AAAOTUlEQVTRyMHTGjloWiNzp9Qzu62ehM7Ri4jsFxV0GRex\nWIwZzbXMaJ7ByYfOeNW6Tbt6eWrjbp7b3MULW3t4bks3T27YxW86XyEcuQcgHgseSjN/agNz2uqZ\nP62BuVMamNNWx/ypjUxvSql3LyIyAhV0KbkDWuo4oKXuNYW+t3+Al3fsYd22HtZu7eGl7T28GL5e\n9eKOV/XsAepq4sxsqWPelAZmt9Uxq6WOuVMbmNVSx6zWOma31dNUq19pEalO+tdPyqauJsEhM4Jz\n60Plcjm6+jKs3RoU+fU79vDS9qD4v7K7l9Xrd7Kjp/8126WScea01TOloYameD/znsowZ0o9UxpS\nzG6rp6UuyZy2elrqa6ir0XPlRaRyqKDLpBSLxWiuq+GwOa0cNqd12DZ70gNs3NXLum09bOtO8/KO\nPWze3ccru3rZtLuPp7f28fD6l+lJDwy7/dTGFC11SWa11tFWn2JWax0t9TWDyxpTwd9NtUmmN9VS\nn9IBgIhMXiroEln1qQQHT2/k4OmNw67v7Oxk8eLFdKcH2LSrl63daTbv7mNLV9/g39u602za3Ye/\nspu71myitz874ufVJuPUpxIc0FxLU22S+lSCmc11NIavD2iupbE2SUMqwQHNdTSkErQ11DC9qZba\nZFzX64tISamgS0WLxWI01SZpmtHEwhn7bp/L5di0u4+de/oHC35Xb4aNu3rZkx5gR0+wvC+TZXtP\nmuc3d9ObybKjJ/2qCX7Daa5LMq0xRV1NghnNtbTUBcP+M1uCA4Gm2iQzW2qpq0nQXJfkgOa6wYOI\n5rqa8flCRKRiqaCLFIjFYsxsqWNmSx2Hzmwuerv+gSxdvRn6Mlm2dAUHBD3hKYGevszgKEFPeoBd\nvf1s3t3H+h172NHTz9bu9D73X1cTpyGVpL4mwfTmWhpTCVLJONObammuS7J753YO3vgM0xpTpJJx\napMJpjelaKxNkkrGaamrYWpjippETFcKiFQoFXSRcVCTiDOlMQUET7sbi1wuR18my9buNDt60vT2\nZ9m0q5fu9AB9mQG2dqXZuaefdDgqsL0nTTqTZVt3mtUv76Qvk2VPOkNm9c6iPi+ViNNSn6StIUUq\nEacmGae5NsmUsOCnEsGowPSmWlKJOMlEjJpEcPDQkEoMvm9IJZjWWDv4viYRoy6Z0P3+RcpEBV2k\nzGKxGHU1Cea01TOnrX6/9tHZ2cnsgxbRlc6QzmTZ3Rv0/NOZLOlMlk27+9iTzpAeyNHXP8Cm3X30\nZQZIZ3L0ZQYGRwzSA0H7rd3pwXv4j0UqPDhIJmIk40GRb2tI0VSwLBmP0VibZGpjDYnwfbAuxrSm\nWuprEiTiwftEPEYqGWdaYy2pZJxEHF7e1U/Tth4S8Rit9TU06lJFEUAFXaRitDbU0NowPufas9kc\n6YEsmWyO/kyWrr4M27rTZLJZ0pkcmWyWzbv76O3Pkslm6R/I0dsfHBj0D2TJDOTIZMNlXX30pDNk\nsjkyAzn6B4LTEulMlv5sjoHwz9ise9W7ZDxGvOAgoCYRZ2pjKpiMGC5LxuPE49CYStLaUDO4PBGP\nkYjFSMSDkYum2uTguvw+47EYLfU1NNcm9y4b3C5GbTL4vPxnJMJt8vvWqIVMBBV0EXmNeDxGXTy8\nTK8WpjSmmDe1oWSfl83mBucfZLI5BsKDhIFsjp17+unqyzCQDQ4S1r30EjNnzQ5GErqCA4iBXLBu\nYCDHQC5HV2+GnXv6g4OFXLCf/MHE81u66ctkyYbbZMP99mUGRr3K4fWoTcaZ0pAKDxIIin3s1QcF\nU8P5D8GBAHR1ddG2ak/YNviZtNbX0JBKkIgFcyGCAwde9ToeizGtKUUqkRh2XSy294AjGY8xpTE1\neNAydH1++/y2TXVJanS1xqQ1KQu6mcWB7wJHAn3AB939mfJGJSKlEo/HqE8lijpo6EztpL19bkni\n6Eln6B/YW+Sz4cFAcBqi71XrBnLB64Fsjh09/fSkMwzkgoOT/EFEvu3W7mBEYiAbzJkYXJ/Lkc1C\nV1+G3b394fKgTc+eNBt6dpHLMRjDtu508Lm5HLmxnxEZF7XhQUfhAUJ8hAOA1vAGTrHwfX59jPB9\neHDT3d1N8/27B9e31AWXgha2ze8DCvcVLsvHEq5ra6ihNhmHcFnQJBb+vfc9g+/DbeN721GwPBYL\n5slMa0yRTMQHD8KSiSDv/BUs5b40dVIWdOAvgDp3P8HMjge+DpxV5phEpMI1pEb+J3HBCPc7KJXO\nzk7a29tHXJ/L5cjmGDzoyIWv9/QPDF5GOXRdNjw4yG+7a08/Pf0D4fvg4GIgl3vVvrO54LMKDyhy\n4YFLvs1w7fOXdubf741hbxz9A8H77nSWgT39g5/zxOB24bYweBCT/zv/mTmCvwnX5R/tXA6JeIwZ\nTbUcNK2Bkw+dwbnLFkzoHI/JWtBPBH4N4O4PmNkxZY5HRGRSiYVD8QliFN7FuDG8s2GU7OvgZSwG\nsjm296SDok+O8L/B97nB93tHOQrXZcMDiGDd3vY7evrZ0z+wd4Qm/JPJZtnSlaanL0NXOsP6Hb34\nxl189XZnW3eaS/7sjeOSVzFiuXKN24zCzK4GbnH328L3LwIL3X3waR0dHR25hobxO6fX29tLXd3Y\nLjeKqmrJtVryBOVaiaolT6jMXK98cAszm5KcvaRtcNnrzbOnp4elS5eOOMNysvbQdwGFd/WIFxbz\nvPE6ooPxPUKc7Kol12rJE5RrJaqWPKEyc718mHReb54dHR2jrp+s0xXvBU4HCM+hP17ecERERCa3\nydpDvxV4h5ndRzAJ8QNljkdERGRSm5QF3d2zwEfLHYeIiEhUTNYhdxERERkDFXQREZEKoIIuIiJS\nAVTQRUREKoAKuoiISAVQQRcREakAk/LWr8Xo6OiIZuAiIiL7abRbv0a2oIuIiMheGnIXERGpACro\nIiIiFWBS3vp1IplZHPgucCTQB3zQ3Z8pb1TFMbMa4FpgAVALfBF4EriO4BG+q4Hz3T1rZpcCZwAZ\n4EJ3f8jMFhXbdiLzGo2ZHQB0AO8giO86KixXM/tH4EwgRfC7eTeVmWcNcD3B7+8A8CEq8GdqZscB\nX3b35WOJeTzaljHPo4BvE/xc+4C/cfdXzOxDwEfC2L/o7r80s+nADUA9sB74gLv3jKXtROYJr861\nYNl7gU+6+wnh+wnPVT10+AugLvwhfAb4epnjGYtzgK3ufhJwGnAF8A3g4nBZDDjLzI4GTgGOA94D\nfCfcfixtyy4sAP8B7AkXVVyuZrYcWAa8hSC2eVRgnqHTgaS7LwP+CfgXKixXM/sH4Gog/xDsUuX3\nmralzq3QMHl+i6C4LQd+ClxkZrOAvyP43V4BfMnMaoHPAzeEsa8CPjKWthOU4qBhciU8gPlbgu+e\ncuWqgg4nAr8GcPcHgGPKG86Y3ARcUvA+Aywl6NEB3Aa8nSDHO9w95+4vAkkzmzHGtpPB14CrCI5W\noTJzXUHwuOBbgV8Av6Qy8wRYQxBLHGgB+qm8XJ8Fzi54X6r8hms7kYbm+R53fzR8nQR6gTcD97p7\nn7vvBJ4BjqDg32D2xj6WthPtVbma2TTg34ALC9qUJVcV9OAfkp0F7wfMLBKnIty9y913m1kzcDNw\nMRBz9/ylC7uBVl6bY375WNqWlZmdC2x299sLFldirtMJDirfRfDEwR8B8QrME6CLYLj9KeB7wOVU\n2M/U3W8hOFDJK1V+w7WdMEPzdPcNAGa2DPgE8E1Gjr1w+b7yHK7thCrM1cwSwDXA/wrjyStLriro\nsAtoLngfd/dMuYIZKzObB/wO+C93vwEoPG/WDOzgtTnml4+lbbmdB7zDzO4CjgJ+ABxQsL5Sct0K\n3O7uaXd3gp5N4f/IlZInBP8I3u7uhxLMYbmeYN5AXiXlmleq/z+Ha1tWZvZughG1M9x9MyPHXrh8\nX3kO17aclgJvAK4E/ht4o5n9O2XKVQUd7iU4l4eZHU8w3BkJZjYTuAO4yN2vDRevCs/DQnBefSVB\njivMLG5m8wkOWraMsW1ZufvJ7n5KeE7uUeBvgNsqMNffA39qZjEzmw00Ar+twDwBtrO3B7INqKFC\nf38LlCq/4dqWjZmdQ9AzX+7uz4WLHwJOMrM6M2sF2gkm8A3+G8ze2MfStmzc/SF3XxL+u/Qe4El3\nv5Ay5RqJoeUSu5Wg53cfwYSGD5Q5nrH4LDAFuMTM8ufSLwAuN7MU0Anc7O4DZrYSuJ/gIO78sO2n\ngO8V2XYyGkv8kcg1nN16MsH/5PmYnqfC8gx9E7g2jC1F8Pv8MJWZa16pfmdf03bCMhoiHIa+HHgR\n+KmZAdzt7pea2eUEhSkOfM7de83si8D1Fsz03gK81927i2074QkWwd03liNX3SlORESkAmjIXURE\npAKooIuIiFQAFXQREZEKoIIuIiJSAVTQRUREKoAuWxOR/D3kbyR4uE+O4C5VzwF/7e7pMexno7vP\nKkmQIjIqFXQRybvT3d+Tf2NmNxA89a1s1zSLSPFU0EXkNcIblBwIbDezqwme+jYNuM3dLzGz6wge\ni7kgbHeuuz9SsP2/Etyy9hMF9xgXkRLSOXQRyXubmd1lZk8CjxDcRfFZ4AF3X0Hw9KePFbRfGy7/\nNvDh/EIz+xrBY1HPVzEXmTgq6CKSd2d4T+qTgDTBLWe3Acea2Y8IbtVaW9B+Vfj3OvY+G3omwaMf\nmyYiYBHZSwVdRF7F3bcC5wBXEzwRbYe7/zXwdaDBzGJh0+F6368QPNN9iZn96UTEKyIBFXQReQ13\nf5LgARuHAaeHDy+6EngamL2PbXMEj7u9wsymlTpWEQno4SwiIiIVQD10ERGRCqCCLiIiUgFU0EVE\nRCqACrqIiEgFUEEXERGpACroIiIiFUAFXUREpAKooIuIiFSA/w8Z6YDlwkTYeQAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 4.5))\n",
    "ax.plot(np.arange(len(reviews_per_user)), reviews_per_user.values);\n",
    "ax.set_ylabel('Rated Movies')\n",
    "ax.set_xlabel('Rank')\n",
    "ax.set_title('Distribution of ratings for all users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar story as before, some users have rated a lot of movies. Tough this distribution has a fatter tail, meaning manu users have actually rated a medium amount of movies.\n",
    "\n",
    "Anyway, let's only keep 20,000 users to start with. 10,000 for training and 10,000 for a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_to_keep = np.random.choice(reviews_per_user.index.values, 20000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_users, test_users = users_to_keep[:10000], users_to_keep[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = top_movies_df.loc[top_movies_df.loc[:,'userId'].isin(train_users),:]\n",
    "test_df = top_movies_df.loc[top_movies_df.loc[:,'userId'].isin(test_users),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set consists of 6.21 % of all reviews\n",
      "Test set consists of 6.02 % of all reviews\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set consists of %.2f %% of all reviews\" % (100 * train_df.shape[0] / movielens_df.shape[0]))\n",
    "print(\"Test set consists of %.2f %% of all reviews\" % (100 * test_df.shape[0] / movielens_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now the set of reviews we need to handle is drastically reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting ratings\n",
    "The task I am tackeling in this notebook is to predict movie ratings for movies that a user did not yet watch. This will be done based on how users with similar taste in movies have rated the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Recommendation Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give all users a new index staring at 0, for easier storing in matrix format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_ids = dict(zip(train_df.loc[:,'userId'].unique(), range(train_df.loc[:,'userId'].nunique())))\n",
    "test_user_ids = dict(zip(test_df.loc[:,'userId'].unique(), range(test_df.loc[:,'userId'].nunique())))\n",
    "\n",
    "movie_ids = dict(zip(top_movies, range(len(top_movies))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gustav\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\Gustav\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "# Relabel Users\n",
    "train_df.loc[:,'newUserId'] = train_df.loc[:,'userId'].apply(lambda x: train_user_ids[x])\n",
    "test_df.loc[:,'newUserId'] = test_df.loc[:,'userId'].apply(lambda x: test_user_ids[x])\n",
    "\n",
    "# Relabel Movies\n",
    "train_df.loc[:,'newMovieId'] = train_df.loc[:,'movieId'].apply(lambda x: movie_ids[x])\n",
    "test_df.loc[:,'newMovieId'] = test_df.loc[:,'movieId'].apply(lambda x: movie_ids[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train = scipy.sparse.coo_matrix((train_df.loc[:,'rating'].values, (train_df.loc[:,'newUserId'].values, train_df.loc[:,'newMovieId'].values)), shape=(10000, 2500))\n",
    "R_train = scipy.sparse.csr_matrix(R_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_test = scipy.sparse.coo_matrix((test_df.loc[:,'rating'].values, (test_df.loc[:,'newUserId'].values, test_df.loc[:,'newMovieId'].values)), shape=(10000, 2500))\n",
    "R_test = scipy.sparse.csr_matrix(R_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un-weighted averages\n",
    "First, let's make predictions $\\hat{r}_{i,j}$ about what ratings user $i$ will give movie $j$ simply by averaging over all other predictions:\n",
    "$$\\hat{r}_{i,j}= \\bar{r}_i + \\frac{\\sum_{i'\\in \\Omega_j}r_{i',j} - \\bar{r}_{i'}}{|\\Omega_j|},$$\n",
    "where $r_{i,j}$ is the rating given by user $i$ for movie $j$, $\\bar{r}_i$ is the average of all ratings user $i$ has given so far, $\\Omega_j$ is the set of all users who have rated movie $j$.\n",
    "Esentially, we predict ratings for each user-movie pair as the users mean rating plus the movies average deviation from raters mean ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by calculating the avereage rating for all users: $\\bar{r}_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rhat\n",
    "R_train_user_mean = R_train.sum(1) / (R_train != 0).sum(1)\n",
    "R_train_user_mean_vec = np.asarray(R_train_user_mean).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating $\\frac{\\sum_{i'\\in \\Psi_j}r_{i',j} - \\bar{r}_{i'}}{|\\Psi_j|}$ is trickier since it requires subtracting the row means only from non-zero ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elementwise subtraction of the user means (adapted from https://stackoverflow.com/questions/19017804/scipy-sparse-matrix-special-substraction)\n",
    "non_zero_per_row = np.diff(R_train.indptr)\n",
    "\n",
    "R_train_deviations = scipy.sparse.csr_matrix((R_train.data - np.repeat(R_train_user_mean_vec, non_zero_per_row), R_train.indices, R_train.indptr),\n",
    "                   shape=R_train.shape)\n",
    "\n",
    "R_train_movie_mean_deviations = R_train_movie_mean_dev.sum(0) / (R_train != 0).sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, piece the two vectors together to calculate the matrix $\\hat{R}$, with elements $\\bar{r}_{i,j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_train_predictions = R_train_user_mean + R_train_movie_mean_deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though, since we can only evaluate movies that users have actually rated, let's also create a vector of predictions that we call $\\hat{Y}$, that we can use to compare to the ectual reviews $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat = np.asarray(R_train_predictions[R_train.nonzero()]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1241462,)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = R_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1241462,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on training set, no weighting: 0.7395\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE on training set, no weighting: %.4f\" % mean_squared_error(Y_train, Y_train_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted averages\n",
    "When predicting ratings with weighted averages, we consider the ratings made by similar users as being more relevant. Predictions are made with:\n",
    "$$\\hat{r}_{i,j}= \\bar{r}_i + \\frac{\\sum_{i'\\in \\Omega_j}w_{i,i'}(r_{i',j} - \\bar{r}_{i'})}{\\sum_{i'\\in\\Omega_j}|w_{i,i'}|},$$\n",
    "where $w_{i,i'}$ is a weight how how similar users $i$ and $i'$ are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_train = cosine_similarity(R_train_deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a naive implementation of the predict function that simply predicts the rating for a single user-movie pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(user_id, movie_id, R_deviations, W, R_user_mean):\n",
    "    \n",
    "    return (R_user_mean[user_id] + (W[user_id] * R_deviations[:,movie_id].toarray().flatten()).sum() / np.absolute(W[user_id]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above implementation ended up being increadibly slow, so let's improve it by calculating all predictions for one user at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_user(user_id, R_deviations, W, R_user_mean):\n",
    "    weighted_deviations = R_deviations.T.multiply(W[user_id]).T\n",
    "    \n",
    "    return R_user_mean[user_id] + weighted_deviations.sum(0) / np.absolute(W[0]).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9692634523529975"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(0, 10, R_train_deviations, W_train, R_train_user_mean_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9692634523529975"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_user(0, R_train_deviations, W_train, R_train_user_mean_vec)[0,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [14:30<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "R_train_predictions_weighted = np.zeros((10000, 2500))\n",
    "for i in tqdm(range(10000)):\n",
    "    R_train_predictions_weighted[i,:] = pred_user(i, R_train_deviations, W_train, R_train_user_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_hat_weighted = np.asarray(R_train_predictions_weighted[R_train.nonzero()]).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I am weighting contributions to the prediction based on user similarities, I expect results to be better.\n",
    "However, for the training set the effect will probably be inflated, since users will de deemed to be very similar to themselves, and thus leak their actual ratings into the predictions to a larger extend compared to when no weights were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on training set, with user similarity weighting: 0.7890\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE on training set, with user similarity weighting: %.4f\" % mean_squared_error(Y_train, Y_train_hat_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, thsi result is actually worse compared to that of simply taking the average, and it came at a significant computational cost...\n",
    "\n",
    "Let's see what happens if we only consider the k closest neighbours to a user when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_user_from_k_neighbours(user_id, R_deviations, W, R_user_mean, k):\n",
    "    \n",
    "    # Since we are filtering out users, let's also filter out the actual user we are predicting.\n",
    "    k_closest_users = np.argpartition(W[user_id], -k-1)[-k-1:]\n",
    "    k_closest_users = np.delete(k_closest_users, np.where(k_closest_users == user_id))\n",
    "    \n",
    "    weighted_deviations = R_deviations[k_closest_users].T.multiply(W[user_id,k_closest_users]).T\n",
    "    \n",
    "    return R_user_mean[user_id] + np.nan_to_num((weighted_deviations.sum(0) / np.absolute(W[user_id,k_closest_users]).sum(0)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.914548393149484"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_user_from_k_neighbours(0, R_train_deviations, W_train, R_train_user_mean_vec, 50)[0,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|                                                     | 3023/10000 [00:05<00:11, 597.61it/s]C:\\Users\\Gustav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if __name__ == '__main__':\n",
      "100%|| 10000/10000 [00:16<00:00, 623.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "R_train_predictions_neighbours = np.zeros((10000, 2500))\n",
    "for i in tqdm(range(10000)):\n",
    "    R_train_predictions_neighbours[i,:] = pred_user_from_k_neighbours(i, R_train_deviations, W_train, R_train_user_mean, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on training set, with user similarity weighting and 50 neighbours: 0.6629\n"
     ]
    }
   ],
   "source": [
    "Y_train_hat_neighbours = np.asarray(R_train_predictions_neighbours[R_train.nonzero()]).reshape(-1)\n",
    "print(\"MSE on training set, with user similarity weighting and 50 neighbours: %.4f\" % mean_squared_error(Y_train, Y_train_hat_neighbours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvement! And the computational cost is also much lower comapred to taking the full weighted average. Also, this is actually the first method where I did not allow the model to peek at the users own ratings.\n",
    "\n",
    "Anyway, we should not evaluate on the test set, let's try the test set instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un-weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rhat\n",
    "R_test_user_mean = R_test.sum(1) / (R_test != 0).sum(1)\n",
    "R_test_user_mean_vec = np.asarray(R_test_user_mean).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_test_predictions = R_test_user_mean + R_train_movie_mean_deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though, since we can only evaluate movies that users have actually rated, let's also create a vector of predictions that we call $\\hat{Y}$, that we can use to compare to the ectual reviews $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_hat = np.asarray(R_test_predictions[R_test.nonzero()]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = R_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test set, without weights: 0.8899\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE on test set, without weights: %.4f\" % mean_squared_error(Y_test, Y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse than the training result, as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't need the test set deviations for the un-weighted approach, but now we need them to calculate user similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Elementwise subtraction of the user means (adapted from https://stackoverflow.com/questions/19017804/scipy-sparse-matrix-special-substraction)\n",
    "non_zero_per_row = np.diff(R_test.indptr)\n",
    "\n",
    "R_test_deviations = scipy.sparse.csr_matrix((R_test.data - np.repeat(R_test_user_mean_vec, non_zero_per_row), R_test.indices, R_test.indptr),\n",
    "                   shape=R_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate similarity of users in the test set and the training set. $W_{i,j}$ will be the similarity of user $i$ in the test set and user $j$ in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_test = cosine_similarity(R_test_deviations, R_train_deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions should be made based on the average rating of a user in the test set, it's similarity to users in the training set, and the ratings users in the training set has made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0367859266880854"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(0, 10, R_train_deviations, W_test, R_test_user_mean_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [11:53<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "R_test_predictions_weighted = np.zeros((10000, 2500))\n",
    "for i in tqdm(range(10000)):\n",
    "    R_test_predictions_weighted[i,:] = pred_user(i, R_train_deviations, W_test, R_test_user_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_hat_weighted = np.asarray(R_test_predictions_weighted[R_test.nonzero()]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on testing set, with user similarity weighting: 0.7660\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE on testing set, with user similarity weighting: %.4f\" % mean_squared_error(Y_test, Y_test_hat_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, this is actually a better result compared to what we got on the training set. Fishy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to modify the k-neighbour approach, since it is no longer relevant to filter out the user we are predicting ratings for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_user_from_k_neighbours_test(user_id, R_deviations, W, R_user_mean, k):\n",
    "    \n",
    "    k_closest_users = np.argpartition(W[user_id], -k)[-k:]\n",
    "    \n",
    "    weighted_deviations = R_deviations[k_closest_users].T.multiply(W[user_id,k_closest_users]).T\n",
    "    \n",
    "    return R_user_mean[user_id] + np.nan_to_num((weighted_deviations.sum(0) / np.absolute(W[user_id,k_closest_users]).sum(0)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|                                                                   | 1139/10000 [00:01<00:15, 589.86it/s]C:\\Users\\Gustav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if __name__ == '__main__':\n",
      "100%|| 10000/10000 [00:16<00:00, 623.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "R_test_predictions_neighbours = np.zeros((10000, 2500))\n",
    "for i in tqdm(range(10000)):\n",
    "    R_test_predictions_neighbours[i,:] = pred_user_from_k_neighbours(i, R_train_deviations, W_test, R_test_user_mean, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on testing set, with user similarity weighting and 50 neighbours: 0.6580\n"
     ]
    }
   ],
   "source": [
    "Y_test_hat_neighbours = np.asarray(R_test_predictions_neighbours[R_test.nonzero()]).reshape(-1)\n",
    "print(\"MSE on testing set, with user similarity weighting and 50 neighbours: %.4f\" % mean_squared_error(Y_test, Y_test_hat_neighbours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, again we see better results compared to what we got on the training set..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens with fewer neighbours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|                                                                   | 1141/10000 [00:01<00:14, 624.92it/s]C:\\Users\\Gustav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if __name__ == '__main__':\n",
      "100%|| 10000/10000 [00:16<00:00, 605.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "R_test_predictions_neighbours_25 = np.zeros((10000, 2500))\n",
    "for i in tqdm(range(10000)):\n",
    "    R_test_predictions_neighbours_25[i,:] = pred_user_from_k_neighbours(i, R_train_deviations, W_test, R_test_user_mean, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on testing set, with user similarity weighting and 25 neighbours: 0.6493\n"
     ]
    }
   ],
   "source": [
    "Y_test_hat_neighbours_25 = np.asarray(R_test_predictions_neighbours_25[R_test.nonzero()]).reshape(-1)\n",
    "print(\"MSE on testing set, with user similarity weighting and 25 neighbours: %.4f\" % mean_squared_error(Y_test, Y_test_hat_neighbours_25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better!\n",
    "\n",
    "Still, I find it very fishy that we get better results on the test set compared to the training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
